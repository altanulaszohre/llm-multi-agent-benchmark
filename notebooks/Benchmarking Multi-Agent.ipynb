{"cells":[{"cell_type":"markdown","source":["# **Benchmarking Multi-Agent Coordination for Energy Planning**"],"metadata":{"id":"yahoRz0IHyrf"}},{"cell_type":"code","source":["!pip -q install openai numpy pandas scikit-learn\n","\n","import os\n","import json\n","import re\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","from dataclasses import dataclass, asdict\n","from typing import List, Dict, Any\n","from sklearn.ensemble import RandomForestRegressor\n","from openai import OpenAI\n","\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","\n","os.environ[\"GROQ_API_KEY\"] = \"PUT_YOUR_KEY_HERE\"\n","\n","client = OpenAI(\n","    base_url=\"https://api.groq.com/openai/v1\",\n","    api_key=os.environ[\"GROQ_API_KEY\"]\n",")\n","LLM_MODEL = \"llama-3.1-8b-instant\"\n","\n","LLM_TEMPERATURE = 0.25\n","LLM_MAX_TOKENS = 350\n","LLM_RETRIES = 2\n","HARD_SECURITY = 0.90\n","\n","url = \"https://github.com/owid/energy-data/raw/master/owid-energy-data.csv\"\n","try:\n","    df = pd.read_csv(url)\n","except:\n","    if os.path.exists(\"/content/owid-energy-data.csv\"):\n","        df = pd.read_csv(\"/content/owid-energy-data.csv\")\n","    else:\n","        data = {\n","            'iso_code': ['AUT']*30 + ['BEL']*30,\n","            'country': ['Austria']*30 + ['Belgium']*30,\n","            'year': list(range(2000, 2030))*2,\n","            'electricity_demand': np.random.uniform(50, 100, 60),\n","            'carbon_intensity_elec': np.random.uniform(200, 400, 60),\n","            'low_carbon_share_elec': np.random.uniform(10, 50, 60),\n","            'fossil_share_elec': np.random.uniform(10, 50, 60),\n","            'net_elec_imports_share_demand': np.random.uniform(-10, 10, 60)\n","        }\n","        df = pd.DataFrame(data)\n","\n","df = df[~df[\"iso_code\"].astype(str).str.startswith(\"OWID_\")].copy()\n","df[\"year\"] = df[\"year\"].astype(int)\n","\n","@dataclass\n","class Episode:\n","    episode_id: str\n","    country: str\n","    iso_code: str\n","    train_years: np.ndarray\n","    test_years: np.ndarray\n","    demand_train: np.ndarray\n","    demand_test: np.ndarray\n","    intensity_train: np.ndarray\n","    intensity_test: np.ndarray\n","    base_low_carbon_pct: float\n","    base_fossil_pct: float\n","    base_net_import_pct: float\n","    w_cost: float\n","    w_emission: float\n","    w_security: float\n","    budget_cap: float\n","    max_emission: float\n","    min_security: float\n","\n","@dataclass\n","class Plan:\n","    renewable_invest: float\n","    storage_invest: float\n","    demand_response: float\n","    carbon_tax: float\n","    def clip(self):\n","        self.renewable_invest=float(np.clip(self.renewable_invest,0,1))\n","        self.storage_invest=float(np.clip(self.storage_invest,0,1))\n","        self.demand_response=float(np.clip(self.demand_response,0,1))\n","        self.carbon_tax=float(np.clip(self.carbon_tax,0,1))\n","        return self\n","\n","PLAN_SCHEMA = [\"renewable_invest\", \"storage_invest\", \"demand_response\", \"carbon_tax\"]\n","\n","def build_episodes(df, n=30):\n","    episodes = []\n","    valid_iso = df.groupby(\"iso_code\").filter(lambda x: x[\"year\"].max() >= 2022 and len(x) > 25)[\"iso_code\"].unique()\n","\n","    candidates = []\n","    for iso in valid_iso:\n","        sub = df[df.iso_code == iso]\n","        count = sub[\"electricity_demand\"].notna().sum()\n","        candidates.append((iso, count))\n","\n","    candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:n]\n","    top_isos = [x[0] for x in candidates]\n","\n","    for iso in top_isos:\n","        sub = df[df.iso_code == iso].sort_values(\"year\").copy()\n","        sub[\"electricity_demand\"] = sub[\"electricity_demand\"].ffill().fillna(0)\n","        sub[\"carbon_intensity_elec\"] = sub[\"carbon_intensity_elec\"].ffill().fillna(400)\n","\n","        train = sub[sub.year.between(2000, 2018)]\n","        test = sub[sub.year.between(2019, 2023)]\n","\n","        if len(train) < 10 or len(test) < 2:\n","            continue\n","\n","        last = train.iloc[-1]\n","\n","        episodes.append(Episode(\n","            episode_id=f\"{iso}_Medium\",\n","            country=sub.iloc[0][\"country\"],\n","            iso_code=iso,\n","            train_years=train.year.values,\n","            test_years=test.year.values,\n","            demand_train=train.electricity_demand.values,\n","            demand_test=test.electricity_demand.values,\n","            intensity_train=train.carbon_intensity_elec.values,\n","            intensity_test=test.carbon_intensity_elec.values,\n","            base_low_carbon_pct=float(last.get(\"low_carbon_share_elec\", 10)),\n","            base_fossil_pct=float(last.get(\"fossil_share_elec\", 80)),\n","            base_net_import_pct=float(last.get(\"net_elec_imports_share_demand\", 0)),\n","            w_cost=0.4, w_emission=0.4, w_security=0.2,\n","            budget_cap=0.60,\n","            max_emission=0.45,\n","            min_security=0.90\n","        ))\n","    return episodes\n","\n","def evaluate_plan(ep: Episode, plan: Plan, demand_forecast: np.ndarray) -> Dict[str, float]:\n","    MAX_DEM = np.max(ep.demand_train) * 1.5 if len(ep.demand_train)>0 else 100\n","    avg_dem = np.mean(demand_forecast) * (1 - 0.2*plan.demand_response)\n","\n","    base_int = np.mean(ep.intensity_train) if len(ep.intensity_train) else 400\n","    red = (plan.renewable_invest * 0.6) + (plan.carbon_tax * 0.2)\n","    curr_int = base_int * (1 - red)\n","    emission = np.clip((curr_int / 800) * (avg_dem/MAX_DEM), 0, 1)\n","\n","    base_cost = 0.3*plan.renewable_invest + 0.4*plan.storage_invest + 0.1*plan.carbon_tax\n","    grid_penalty = 0.0\n","    if plan.renewable_invest > (plan.storage_invest + 0.1):\n","        grid_penalty = 0.15\n","    cost = np.clip(base_cost + grid_penalty, 0, 1)\n","\n","    sec_base = 0.85\n","    storage_bonus = 0.55 * plan.storage_invest\n","    renewable_penalty = 0.10 * plan.renewable_invest\n","    sec = np.clip(sec_base + storage_bonus - renewable_penalty, 0, 1)\n","\n","    budget_over = max(0.0, cost - ep.budget_cap) / max(1e-6, (1.0 - ep.budget_cap))\n","    emission_over = max(0.0, emission - ep.max_emission) / max(1e-6, (1.0 - ep.max_emission))\n","    security_under = max(0.0, ep.min_security - sec) / max(1e-6, ep.min_security)\n","\n","    total_violation = float(budget_over + emission_over + security_under)\n","    any_violation = float(total_violation > 1e-9)\n","\n","    return {\n","        \"cost\": float(cost),\n","        \"emission\": float(emission),\n","        \"security\": float(sec),\n","        \"violations\": float(total_violation),\n","        \"any_violation\": float(any_violation),\n","    }\n","\n","def score(ep: Episode, met: dict) -> float:\n","    base_score = ep.w_cost*(1-met[\"cost\"]) + ep.w_emission*(1-met[\"emission\"]) + ep.w_security*(met[\"security\"])\n","    k = 0.9\n","    penalty = float(np.exp(-k * met[\"violations\"]))\n","    return float(base_score * penalty)\n","\n","def forecast_ml(ep: Episode):\n","    X_train, y_train = [], []\n","    for i in range(1, len(ep.train_years)):\n","        prev_demand = ep.demand_train[i-1]\n","        year = ep.train_years[i]\n","        target = ep.demand_train[i]\n","        X_train.append([year, prev_demand])\n","        y_train.append(target)\n","\n","    X_train = np.array(X_train)\n","    y_train = np.array(y_train)\n","\n","    if len(y_train) < 5:\n","        yhat = np.full_like(ep.test_years, np.mean(ep.demand_train), dtype=float)\n","        denom = np.clip(ep.demand_test, 1.0, None)\n","        mape = np.mean(np.abs((ep.demand_test - yhat)/denom)) * 100\n","        return yhat, float(mape)\n","\n","    model = RandomForestRegressor(n_estimators=150, max_depth=8, random_state=SEED)\n","    model.fit(X_train, y_train)\n","\n","    preds = []\n","    last_demand = float(ep.demand_train[-1])\n","    for year in ep.test_years:\n","        feat = np.array([[year, last_demand]])\n","        pred = float(model.predict(feat)[0])\n","        preds.append(pred)\n","        last_demand = pred\n","\n","    yhat = np.array(preds, dtype=float)\n","    denom = np.clip(ep.demand_test, 1.0, None)\n","    mape = float(np.mean(np.abs((ep.demand_test - yhat)/denom)) * 100)\n","    return yhat, mape\n","\n","def llm_call(prompt, system=\"You are an AI assistant.\"):\n","    for _ in range(LLM_RETRIES + 1):\n","        try:\n","            resp = client.chat.completions.create(\n","                model=LLM_MODEL,\n","                messages=[{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":prompt}],\n","                temperature=LLM_TEMPERATURE,\n","                max_tokens=LLM_MAX_TOKENS\n","            )\n","            return resp.choices[0].message.content\n","        except Exception:\n","            time.sleep(1.0)\n","    return \"{}\"\n","\n","def extract_json(text: str) -> Dict[str, Any]:\n","    if not isinstance(text, str):\n","        return {}\n","    text = text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n","    start = text.find(\"{\")\n","    end = text.rfind(\"}\")\n","    if start == -1 or end == -1 or end <= start:\n","        return {}\n","    candidate = text[start:end+1]\n","    try:\n","        return json.loads(candidate)\n","    except:\n","        return {}\n","\n","def get_ai_proposal(agent_name, goal, plan, metrics):\n","    sys = (\n","        f\"You are {agent_name}. Goal: {goal}.\\n\"\n","        \"Return ONLY JSON in this exact format:\\n\"\n","        '{\"candidates\":[{\"delta\":{\"renewable_invest\":0.0,\"storage_invest\":0.0,\"demand_response\":0.0,\"carbon_tax\":0.0}},'\n","        '{\"delta\":{\"renewable_invest\":0.0,\"storage_invest\":0.0,\"demand_response\":0.0,\"carbon_tax\":0.0}}]}\\n'\n","        \"Rules:\\n\"\n","        \"- Each delta value must be in [-0.15, +0.15]\\n\"\n","        \"- In EACH candidate, at least ONE value must be NON-ZERO (e.g., 0.03)\\n\"\n","        \"- Keep changes small and safe.\\n\"\n","    )\n","    prompt = f\"Current plan: {asdict(plan)}\\nCurrent metrics: {metrics}\\nPropose 2 candidate deltas.\"\n","    res = llm_call(prompt, sys)\n","    d = extract_json(res)\n","\n","    cands = d.get(\"candidates\", [])\n","    out = []\n","    if isinstance(cands, list):\n","        for c in cands[:2]:\n","            dd = c.get(\"delta\", {}) if isinstance(c, dict) else {}\n","            clean = {}\n","            if isinstance(dd, dict):\n","                for k, v in dd.items():\n","                    if k in PLAN_SCHEMA:\n","                        try:\n","                            clean[k] = float(np.clip(float(v), -0.15, 0.15))\n","                        except:\n","                            pass\n","            out.append(clean)\n","\n","    if not out:\n","        out = [{\"storage_invest\": 0.03}, {\"renewable_invest\": 0.03}]\n","    return out\n","\n","def apply_best_delta(ep: Episode, plan: Plan, yhat: np.ndarray, delta_list: List[Dict[str, float]]) -> Plan:\n","    base_met = evaluate_plan(ep, plan, yhat)\n","    best_s = score(ep, base_met)\n","    best_plan = plan\n","\n","    for d in (delta_list or []):\n","        p_d = asdict(plan)\n","        for k, v in d.items():\n","            if k in p_d:\n","                p_d[k] += float(v)\n","        cand_plan = Plan(**p_d).clip()\n","        cand_met = evaluate_plan(ep, cand_plan, yhat)\n","        cand_s = score(ep, cand_met)\n","        if cand_s > best_s:\n","            best_s = cand_s\n","            best_plan = cand_plan\n","\n","    return best_plan\n","\n","def get_initial_plan():\n","    return Plan(0.20, 0.15, 0.05, 0.05).clip()\n","\n","def run_baseline_monolith(ep: Episode):\n","    t0 = time.time()\n","    yhat, mape = forecast_ml(ep)\n","    plan = Plan(0.22, 0.16, 0.06, 0.06).clip()\n","    met = evaluate_plan(ep, plan, yhat)\n","    return {\"method\":\"baseline_monolith\",\"score\":score(ep,met),\"forecast_mape\":mape,\n","            **{k:met[k] for k in [\"cost\",\"emission\",\"security\",\"violations\"]},\n","            \"messages\":0,\"rounds\":1,\"vetos\":0,\"runtime_sec\":time.time()-t0}\n","\n","def run_single_llm(ep: Episode):\n","    t0 = time.time()\n","    yhat, mape = forecast_ml(ep)\n","    sys = (\n","        \"You are an Energy Planner.\\n\"\n","        \"Return ONLY JSON with fields:\\n\"\n","        '{\"renewable_invest\":0.0,\"storage_invest\":0.0,\"demand_response\":0.0,\"carbon_tax\":0.0}\\n'\n","        \"Values 0..1.\\n\"\n","        f\"Constraints: budget_cost <= {ep.budget_cap}, emission <= {ep.max_emission}, security >= {ep.min_security}.\\n\"\n","    )\n","    prompt = f\"Country: {ep.country}\\nSuggest a plan.\\nCurrent suggestion: {asdict(get_initial_plan())}\\n\"\n","    d = extract_json(llm_call(prompt, sys))\n","    plan = Plan(d.get(\"renewable_invest\",0.22), d.get(\"storage_invest\",0.16),\n","                d.get(\"demand_response\",0.06), d.get(\"carbon_tax\",0.06)).clip()\n","    met = evaluate_plan(ep, plan, yhat)\n","    return {\"method\":\"single_llm_orchestrator\",\"score\":score(ep,met),\"forecast_mape\":mape,\n","            **{k:met[k] for k in [\"cost\",\"emission\",\"security\",\"violations\"]},\n","            \"messages\":1,\"rounds\":1,\"vetos\":0,\"runtime_sec\":time.time()-t0}\n","\n","def run_multi_agent_simple(ep: Episode, rounds=3):\n","    t0 = time.time()\n","    yhat, mape = forecast_ml(ep)\n","    plan = get_initial_plan()\n","    msgs = 0\n","\n","    for r in range(rounds):\n","        met = evaluate_plan(ep, plan, yhat)\n","        cand1 = get_ai_proposal(\"CostAgent\", \"Minimize cost while respecting constraints\", plan, met)\n","        plan = apply_best_delta(ep, plan, yhat, cand1); msgs += 1\n","\n","        met = evaluate_plan(ep, plan, yhat)\n","        cand2 = get_ai_proposal(\"EmissionAgent\", \"Minimize emission while respecting constraints\", plan, met)\n","        plan = apply_best_delta(ep, plan, yhat, cand2); msgs += 1\n","\n","        met = evaluate_plan(ep, plan, yhat)\n","        cand3 = get_ai_proposal(\"SecurityAgent\", \"Maximize security while respecting constraints\", plan, met)\n","        plan = apply_best_delta(ep, plan, yhat, cand3); msgs += 1\n","\n","    met = evaluate_plan(ep, plan, yhat)\n","    return {\"method\":\"multi_agent_simple_agg\",\"score\":score(ep,met),\"forecast_mape\":mape,\n","            **{k:met[k] for k in [\"cost\",\"emission\",\"security\",\"violations\"]},\n","            \"messages\":msgs,\"rounds\":rounds,\"vetos\":0,\"runtime_sec\":time.time()-t0}\n","\n","def run_multi_agent_llm_coord(ep: Episode, rounds=3):\n","    t0 = time.time()\n","    yhat, mape = forecast_ml(ep)\n","    plan = get_initial_plan()\n","    msgs = 0\n","    vetos = 0\n","\n","    for r in range(rounds):\n","        met = evaluate_plan(ep, plan, yhat)\n","\n","        prop_cost = get_ai_proposal(\"CostAgent\", \"Minimize cost while respecting constraints\", plan, met)\n","        prop_emit = get_ai_proposal(\"EmissionAgent\", \"Minimize emission while respecting constraints\", plan, met)\n","        prop_sec  = get_ai_proposal(\"SecurityAgent\", \"Maximize security while respecting constraints\", plan, met)\n","        msgs += 3\n","\n","        is_soft_veto = met[\"security\"] < ep.min_security\n","        is_hard_veto = met[\"security\"] < HARD_SECURITY\n","        p_d = asdict(plan)\n","\n","        if is_hard_veto:\n","            vetos += 1\n","            deficit = (ep.min_security + 0.01) - met[\"security\"]\n","            needed_storage = max(0.0, deficit / 0.55)\n","            p_d[\"storage_invest\"] = float(np.clip(p_d[\"storage_invest\"] + needed_storage, 0, 1))\n","            p_d[\"renewable_invest\"] = float(np.clip(p_d[\"renewable_invest\"] - 0.05 * needed_storage, 0, 1))\n","            plan = Plan(**p_d).clip()\n","            msgs += 1\n","        else:\n","            if is_soft_veto:\n","                merged = (prop_cost or []) + (prop_emit or []) + (prop_sec or [])\n","                plan = apply_best_delta(ep, plan, yhat, merged)\n","                msgs += 1\n","                continue\n","\n","            sys = (\n","                \"You are a Coordinator.\\n\"\n","                \"Return ONLY JSON:\\n\"\n","                '{\"final_delta\":{\"renewable_invest\":0.0,\"storage_invest\":0.0,\"demand_response\":0.0,\"carbon_tax\":0.0}}\\n'\n","                \"Each delta in [-0.15,+0.15].\\n\"\n","            )\n","            proposals = {\"CostAgent\":prop_cost,\"EmissionAgent\":prop_emit,\"SecurityAgent\":prop_sec}\n","            prompt = f\"Plan: {p_d}\\nMetrics: {met}\\nAgent candidates: {proposals}\\nReturn final_delta.\"\n","            d = extract_json(llm_call(prompt, sys)).get(\"final_delta\", {})\n","            msgs += 1\n","\n","            if isinstance(d, dict) and len(d) > 0:\n","                for k, v in d.items():\n","                    if k in p_d:\n","                        try:\n","                            p_d[k] += float(np.clip(float(v), -0.15, 0.15))\n","                        except:\n","                            pass\n","                plan = Plan(**p_d).clip()\n","            else:\n","                merged = (prop_cost or []) + (prop_emit or []) + (prop_sec or [])\n","                plan = apply_best_delta(ep, plan, yhat, merged)\n","\n","        met2 = evaluate_plan(ep, plan, yhat)\n","        if met2[\"security\"] < HARD_SECURITY:\n","            vetos += 1\n","            deficit = (ep.min_security + 0.005) - met2[\"security\"]\n","            needed_storage = max(0.0, deficit / 0.55)\n","            p_d2 = asdict(plan)\n","            p_d2[\"storage_invest\"] = float(np.clip(p_d2[\"storage_invest\"] + needed_storage, 0, 1))\n","            plan = Plan(**p_d2).clip()\n","            msgs += 1\n","\n","    met = evaluate_plan(ep, plan, yhat)\n","    return {\"method\":\"multi_agent_llm_coord\",\"score\":score(ep,met),\"forecast_mape\":mape,\n","            **{k:met[k] for k in [\"cost\",\"emission\",\"security\",\"violations\"]},\n","            \"messages\":msgs,\"rounds\":rounds,\"vetos\":vetos,\"runtime_sec\":time.time()-t0}\n","\n","def run_ablation_no_veto(ep: Episode, rounds=3):\n","    t0 = time.time()\n","    yhat, mape = forecast_ml(ep)\n","    plan = get_initial_plan()\n","    msgs = 0\n","    vetos = 0\n","\n","    for r in range(rounds):\n","        met = evaluate_plan(ep, plan, yhat)\n","\n","        d_cost = get_ai_proposal(\"CostAgent\", \"Minimize cost while respecting constraints\", plan, met)\n","        d_emit = get_ai_proposal(\"EmissionAgent\", \"Minimize emission while respecting constraints\", plan, met)\n","        d_sec  = get_ai_proposal(\"SecurityAgent\", \"Maximize security while respecting constraints\", plan, met)\n","        msgs += 3\n","\n","        sys = (\n","            \"You are a Coordinator (NO VETO ABLATION).\\n\"\n","            \"Return ONLY JSON:\\n\"\n","            '{\"final_delta\":{\"renewable_invest\":0.0,\"storage_invest\":0.0,\"demand_response\":0.0,\"carbon_tax\":0.0}}\\n'\n","        )\n","        prompt = f\"Plan: {asdict(plan)}\\nMetrics: {met}\\nAgent candidates: {{'Cost':{d_cost},'Emission':{d_emit},'Security':{d_sec}}}\\nReturn final_delta.\"\n","        d_final = extract_json(llm_call(prompt, sys)).get(\"final_delta\", {})\n","        msgs += 1\n","\n","        if isinstance(d_final, dict) and len(d_final) > 0:\n","            p_d = asdict(plan)\n","            for k, v in d_final.items():\n","                if k in p_d:\n","                    try:\n","                        p_d[k] += float(np.clip(float(v), -0.15, 0.15))\n","                    except:\n","                        pass\n","            plan = Plan(**p_d).clip()\n","        else:\n","            merged = (d_cost or []) + (d_emit or []) + (d_sec or [])\n","            plan = apply_best_delta(ep, plan, yhat, merged)\n","\n","        met2 = evaluate_plan(ep, plan, yhat)\n","        if met2[\"security\"] < HARD_SECURITY:\n","            vetos += 1\n","\n","    met = evaluate_plan(ep, plan, yhat)\n","    return {\"method\":\"ablation_no_veto\",\"score\":score(ep,met),\"forecast_mape\":mape,\n","            **{k:met[k] for k in [\"cost\",\"emission\",\"security\",\"violations\"]},\n","            \"messages\":msgs,\"rounds\":rounds,\"vetos\":vetos,\"runtime_sec\":time.time()-t0}\n","\n","def run_ablation_no_comm(ep: Episode):\n","    t0 = time.time()\n","    yhat, mape = forecast_ml(ep)\n","    plan = get_initial_plan()\n","    met = evaluate_plan(ep, plan, yhat)\n","\n","    cand = get_ai_proposal(\"CostAgent\", \"Minimize cost while respecting constraints\", plan, met)\n","    plan = apply_best_delta(ep, plan, yhat, cand)\n","\n","    met = evaluate_plan(ep, plan, yhat)\n","    return {\"method\":\"ablation_no_comm\",\"score\":score(ep,met),\"forecast_mape\":mape,\n","            **{k:met[k] for k in [\"cost\",\"emission\",\"security\",\"violations\"]},\n","            \"messages\":1,\"rounds\":1,\"vetos\":0,\"runtime_sec\":time.time()-t0}\n","\n","try:\n","    episodes = build_episodes(df, n=15)\n","    print(f\"Seçilen Ülke Sayısı: {len(episodes)}\")\n","except Exception as e:\n","    print(f\"Bölüm oluşturma hatası: {e}\")\n","    episodes = []\n","\n","results = []\n","\n","if len(episodes) > 0:\n","    print(\"Simülasyon başlıyor (FAIR + High Score + Soft Constraints + Candidate Search)...\")\n","    for i, ep in enumerate(episodes):\n","        print(f\"[{i+1}/{len(episodes)}] İşleniyor: {ep.country} ...\")\n","        results.append({**run_baseline_monolith(ep), \"country\": ep.country})\n","        results.append({**run_single_llm(ep), \"country\": ep.country})\n","        results.append({**run_multi_agent_simple(ep), \"country\": ep.country})\n","        results.append({**run_multi_agent_llm_coord(ep), \"country\": ep.country})\n","        results.append({**run_ablation_no_veto(ep), \"country\": ep.country})\n","        results.append({**run_ablation_no_comm(ep), \"country\": ep.country})\n","\n","    df_res = pd.DataFrame(results)\n","\n","    cols = [\"score\", \"forecast_mape\", \"cost\", \"emission\", \"security\", \"violations\", \"messages\", \"rounds\", \"vetos\", \"runtime_sec\"]\n","    benchmark_mean = df_res.groupby(\"method\")[cols].mean().sort_values(\"score\", ascending=False)\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"BENCHMARK SONUCU (FAIR + High Score + Soft Constraints) - MEAN\")\n","    print(\"=\"*60)\n","    print(benchmark_mean)\n","\n","    benchmark_std = df_res.groupby(\"method\")[cols].std().fillna(0.0)\n","\n","    benchmark_mean.to_csv(\"benchmark_last_results_fair_highscore_mean.csv\")\n","    benchmark_std.to_csv(\"benchmark_last_results_fair_highscore_std.csv\")\n","    df_res.to_csv(\"benchmark_last_results_fair_highscore_raw.csv\", index=False)\n","\n","else:\n","    print(\"Veri hatası.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7LEWgsxUHen","outputId":"498dd1de-4174-4483-98a1-a1ff16dc689c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Seçilen Ülke Sayısı: 15\n","Simülasyon başlıyor (FAIR + High Score + Soft Constraints + Candidate Search)...\n","[1/15] İşleniyor: Austria ...\n","[2/15] İşleniyor: Belgium ...\n","[3/15] İşleniyor: Bulgaria ...\n","[4/15] İşleniyor: Croatia ...\n","[5/15] İşleniyor: Cyprus ...\n","[6/15] İşleniyor: Czechia ...\n","[7/15] İşleniyor: Denmark ...\n","[8/15] İşleniyor: Estonia ...\n","[9/15] İşleniyor: Finland ...\n","[10/15] İşleniyor: France ...\n","[11/15] İşleniyor: Germany ...\n","[12/15] İşleniyor: Greece ...\n","[13/15] İşleniyor: Hungary ...\n","[14/15] İşleniyor: Ireland ...\n","[15/15] İşleniyor: Italy ...\n","\n","============================================================\n","BENCHMARK SONUCU (FAIR + High Score + Soft Constraints) - MEAN\n","============================================================\n","                            score  forecast_mape      cost  emission  \\\n","method                                                                 \n","multi_agent_simple_agg   0.825129       4.377175  0.066667  0.325234   \n","multi_agent_llm_coord    0.814956       4.377175  0.112994  0.307037   \n","ablation_no_comm         0.814954       4.377175  0.112333  0.307340   \n","ablation_no_veto         0.812206       4.377175  0.125000  0.299403   \n","baseline_monolith        0.811204       4.377175  0.136000  0.293990   \n","single_llm_orchestrator  0.792399       4.377175  0.192733  0.282110   \n","\n","                         security  violations   messages  rounds     vetos  \\\n","method                                                                       \n","multi_agent_simple_agg   0.909500    0.000015   9.000000     3.0  0.000000   \n","multi_agent_llm_coord    0.916033    0.000352  12.133333     3.0  0.133333   \n","ablation_no_comm         0.916833    0.000808   1.000000     1.0  0.000000   \n","ablation_no_veto         0.912500    0.000793  12.000000     3.0  0.000000   \n","baseline_monolith        0.916000    0.000000   0.000000     1.0  0.000000   \n","single_llm_orchestrator  0.922667    0.003400   1.000000     1.0  0.000000   \n","\n","                         runtime_sec  \n","method                                \n","multi_agent_simple_agg     34.773282  \n","multi_agent_llm_coord      41.067121  \n","ablation_no_comm           11.670603  \n","ablation_no_veto           44.906687  \n","baseline_monolith           0.336629  \n","single_llm_orchestrator     2.084841  \n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}